{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "# sess = tf.InteractiveSession()\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.contrib import layers, rnn, seq2seq\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_generator import NLUDataGenerator\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple\n",
    "from tensorflow.contrib.legacy_seq2seq import rnn_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 0\n",
    "EOS = 1\n",
    "MASK1_CLASSES = 10\n",
    "MASK2_CLASSES = 10\n",
    "\n",
    "\n",
    "TimeMajor = False\n",
    "batch_size = 32\n",
    "encoder_max_time = 64\n",
    "DataGen = NLUDataGenerator('../data/usr_df_final.csv',\n",
    "                           '../data/ontology_dstc2.json',\n",
    "                           '../data/slots.txt', seq_len = encoder_max_time,\n",
    "                           batch_size = batch_size, time_major=TimeMajor)\n",
    "vocab_size = len(DataGen.vocab)\n",
    "input_embedding_size = 128\n",
    "encoder_hidden_units = 128\n",
    "# decoder_hidden_units = encoder_hidden_units * 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slots_number:  27\n",
      "acts_number:  21\n",
      "vocab_size:  824\n"
     ]
    }
   ],
   "source": [
    "slots_number = len(DataGen.slots_encode)\n",
    "acts_number = len(DataGen.acts_encode)\n",
    "print(\"slots_number: \", slots_number)\n",
    "print(\"acts_number: \", acts_number)\n",
    "print(\"vocab_size: \", DataGen.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "inputs = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "mask1 = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "mask2 = tf.placeholder(shape=(None, None), dtype=tf.int32)\n",
    "lens = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "\n",
    "embeddings = tf.get_variable('embedings', [vocab_size, input_embedding_size], tf.float32)\n",
    "\n",
    "encoded = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "cell = LSTMCell(input_embedding_size)\n",
    "\n",
    "outputs, _ = tf.nn.dynamic_rnn(cell, encoded, sequence_length=lens, dtype=tf.float32)\n",
    "\n",
    "\n",
    "seq_mask = tf.to_float(tf.greater(inputs, PAD))\n",
    "with tf.variable_scope('lm-reg'):\n",
    "    first_words = tf.slice(inputs, [0, 1], [-1, -1])\n",
    "    target = tf.pad(first_words, [[0, 0], [0, 1]])\n",
    "    nwp = layers.fully_connected(outputs, vocab_size, activation_fn=None)\n",
    "    lm_loss = seq2seq.sequence_loss(nwp, target, seq_mask)\n",
    "\n",
    "with tf.variable_scope('mask-pred'):\n",
    "    m1p = layers.fully_connected(outputs, slots_number, activation_fn=None)\n",
    "    m2p = layers.fully_connected(outputs, acts_number, activation_fn=None)\n",
    "    m1_loss = seq2seq.sequence_loss(m1p, mask1, seq_mask)\n",
    "    m2_loss = seq2seq.sequence_loss(m2p, mask2, seq_mask)\n",
    "    \n",
    "    \n",
    "lr = tf.Variable(0.01, trainable=False)\n",
    "opt = tf.train.GradientDescentOptimizer(lr)\n",
    "train_op = opt.minimize(lm_loss + m1_loss + m2_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-b3dc5208cbbe>:2: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5.89 1.35 1.15: 100%|██████████| 500/500 [00:13<00:00, 36.98it/s]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    \n",
    "    avg_loss = -np.ones((3, ))\n",
    "    alpha = 0.9\n",
    "    \n",
    "    pbar = tqdm(range(500))\n",
    "    for step in pbar:\n",
    "        x, m1, m2, _lens = next(DataGen)\n",
    "        \n",
    "        res = sess.run([lm_loss, m1_loss, m2_loss, train_op], {inputs: x, mask1: m1, mask2: m2, lens: _lens})\n",
    "        res = np.array(res[:-1])\n",
    "        \n",
    "        if avg_loss[0] < 0:\n",
    "            avg_loss = res\n",
    "        \n",
    "        avg_loss = alpha * avg_loss + (1-alpha) * res\n",
    "        \n",
    "        pbar.set_description(' '.join('{:.2f}'.format(_) for _ in avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer = tf.summary.FileWriter('../logdir/', sess.graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Это чисто черновик, где происходит какая-то фигня с bi-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None, None), dtype=tf.int32, name='encoder_inputs')\n",
    "encoder_inputs_length = tf.placeholder(shape=(None,), dtype=tf.int32, name='encoder_inputs_length')\n",
    "\n",
    "encoder_targets = tf.placeholder(shape=(None), dtype=tf.int32, name='encoder_targets')\n",
    "embeddings = tf.Variable(tf.random_uniform([vocab_size, input_embedding_size], -1.0, 1.0), dtype=tf.float32)\n",
    "\n",
    "encoder_inputs_embedded = tf.nn.embedding_lookup(embeddings, encoder_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_cell_b = LSTMCell(encoder_hidden_units)\n",
    "encoder_cell_f = LSTMCell(encoder_hidden_units, reuse=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encoder_cell = LSTMCell(encoder_hidden_units, reuse=tf.get_variable_scope().reuse)\n",
    "# encoder_cell_f = LSTMCell(encoder_hidden_units)\n",
    "((encoder_fw_outputs,\n",
    "encoder_bw_outputs),\n",
    "(encoder_fw_final_state,\n",
    "encoder_bw_final_state)) = (tf.nn.bidirectional_dynamic_rnn(cell_fw=encoder_cell_f,\n",
    "                                cell_bw=encoder_cell_b,\n",
    "                                inputs=encoder_inputs_embedded,\n",
    "                                sequence_length=encoder_inputs_length,\n",
    "                                dtype=tf.float32, time_major=TimeMajor))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_outputs = tf.concat((encoder_fw_outputs, encoder_bw_outputs), 2)\n",
    "\n",
    "encoder_final_state_c = tf.concat(\n",
    "    (encoder_fw_final_state.c, encoder_bw_final_state.c), 1)\n",
    "\n",
    "encoder_final_state_h = tf.concat(\n",
    "    (encoder_fw_final_state.h, encoder_bw_final_state.h), 1)\n",
    "\n",
    "encoder_final_state = LSTMStateTuple(\n",
    "    c=encoder_final_state_c,\n",
    "    h=encoder_final_state_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import layers\n",
    "next_word_pred = layers.fully_connected(encoder_outputs, vocab_size, ...)\n",
    "\n",
    "\n",
    "\n",
    "mask1_pred = layers.fully_connected(encoder_outputs, mask1_vocab, ...)\n",
    "mask2_pred = layers.fully_connected(encoder_outputs, mask2_vocab, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_final_state_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_uniform([encoder_hidden_units*2, vocab_size], -1, 1), dtype=tf.float32)\n",
    "b = tf.Variable(tf.zeros([vocab_size]), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.add(tf.matmul(encoder_final_state_h, W), b)\n",
    "# encoder_logits = tf.reshape(encoder_logits_flat, (decoder_max_steps, decoder_batch_size, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = encoder_targets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
